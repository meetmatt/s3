{"name":"Amazon S3","tagline":"Документация и инструменты для переноса файлов на Amazon S3","body":"[Оглавление](index.html) | [Далее](proxy.html \"Настройка прокси\")\r\n\r\n#Подготовка\r\n \r\nВсе шаги перечисленные ниже производятся в панели управления [Amazon Web Services](https://console.aws.amazon.com).\r\n\r\n## S3\r\n\r\n### Создание бакета\r\n\r\nЗаходим в консоль Амазона, переходим в настройки S3.\r\n\r\nЧтобы создать бакет нажимаем на `Create Bucket`:\r\n\r\n![Create Bucket](images/01.png \"Create Bucket\")\r\n\r\nВ открывшемся окне вводим название бакета и выбираем регион `Ireland` (он ближе всего к нашим серверам).\r\n\r\n![New Bucket](images/02.png \"New Bucket\")\r\n\r\nИмя бакета должно быть уникальным, в соответствии с ним создается поддомен вида `bucketname.s3.amazonaws.com`, по которому будут доступны наши файлы. Жмем `Create`.\r\n\r\nЕсли имя бакета не уникально, то будет выведена ошибка.\r\n\r\nПосле создания новый бакет появится в списке слева.\r\n\r\n### Открытие публичного доступа на чтение\r\n\r\nЧтобы файлы, находящиеся в бакете были публично доступны по прямой ссылке необходимо добавить глобальное разрешение в меню `Properties` выбранного бакета.\r\n\r\n![Bucket Permissions](images/03.png \"Bucket Permissions\")\r\n\r\nПо умолчанию авторизованному супер-пользователю доступны все действия с бакетом и объектами в нем.\r\n\r\n![Bucket Permissions](images/04.png \"Bucket Permissions\")\r\n\r\nЧтобы добавить разрешение на чтение файлов для анонимных пользователей выбираем `Add more permissions`, в поле `Grantee` выставляем `Everyone` и ставим флаг `View Permissions`. Сохраняем изменения.\r\n\r\n![Grant Everyone View Permissions](images/05.png \"Allow everyone to view bucket\")\r\n\r\n## Настройка доступа\r\n\r\nДля того чтобы работать с API Amazon Web Services необходимо создать группу, выставить групповые права, создать пользователя и добавить его в группу.\r\n\r\nДля управления пользователями в Amazon используется сервис `Identity and Access Management` (IAM).\r\n\r\n![Identity and Access Management](images/06.png \"Identity and Access Management\")\r\n\r\n### Создание группы\r\n\r\nСоздаем группу перейдя в панель управления группами IAM и нажав `Create New Group`.\r\n\r\n![IAM Groups](images/07.png \"IAM Groups\")\r\n\r\nВводим имя группы.\r\n\r\n![Group name](images/08.png \"Group name\")\r\n\r\nДалее необходимо указать, какие действия и над какими объектами разрешены пользователям группы.\r\n\r\nНам потребуются разрешения на получение списка файлов, чтение, загрузку, удаление и изменение прав файлов.\r\n\r\nЭтим требованиям соответствуют права:\r\n\r\n- ListBucket  \r\n- GetObject  \r\n- PutObject  \r\n- DeleteObject  \r\n- GetObjectAcl  \r\n- PutObjectAcl  \r\n\r\nЧтобы сгенерировать файл с правами, выбираем пункт `Policy Generator`.\r\n\r\n![Policy Generator](images/09.png \"Policy generator\")\r\n\r\nУказываем сервис `Amazon S3` и выбираем указанные выше действия в списке `Actions`.\r\n\r\nВ поле `Amazon Resource Name (ARN)` нужно указать путь до ресурса, в нашем случае это бакет S3.\r\n\r\nНазвание ресурса указывается в формате `arn:aws:SERVICE_NAME:::RESOURCE_NAME`,\r\nсоответсвенно SERVICE_NAME - s3, а RESOURCE_NAME - название бакета, выбранное при создании.\r\n\r\nДопустим бакет называется *mybucket*, в таком случае ARN будет *arn:aws:s3:::mybucket*.\r\n\r\n![Policy Generator Settings](images/10.png \"Policy Generator Settings\")\r\n\r\nВ результате сгенерируется файл с правами, но нам необходимо добавить одну строчку, чтобы все заработало.\r\n\r\n![Generated policy](images/11.png \"Generated policy\")\r\n\r\nВ разделе `Resource` необходимо продублировать строчку с ресурсом `\"arn:aws:s3:::RESOURCE_NAME\"`, но добавив в конце `/*`. Таким образом указанные права будут распространяться не только на сам ресурс (бакет S3 в нашем случае), но так же и на все его содержимое (файлы). В итоге у нас должно быть два ресурса - `\"arn:aws:s3:::RESOURCE_NAME\"` и `\"arn:aws:s3:::RESOURCE_NAME/*\"`, где RESOURCE_NAME - название нашего бакета.\r\n\r\n### Создание пользователя\r\n\r\nПереходим в раздел управления пользователями и нажимаем `Create New Users`.\r\n\r\n![IAM Users](images/12.png \"IAM Users\")\r\n\r\nВводим имя пользователя, убеждаемся что стоит флаг `Generate an access key for each user` и нажимаем `Create`.\r\n\r\n![Create User](images/13.png \"Create User\")\r\n\r\nВ скрытом поле указаны два ключа - `Access Key ID` и `Secret Access Key`. По сути это логин и пароль для работы с API. Сохраняем их в надежном месте.\r\n\r\n![API Credentials](images/14.png \"API Credentials\")\r\n\r\n### Добавление пользователя в группу\r\n\r\nВыбираем созданного пользователя и добавляем его в группу.\r\n\r\n![Add user to groups](images/15.png \"Add user to groups\")\r\n\r\n![Select group](images/16.png \"Select group\")\r\n\r\n\r\n## CloudFront\r\n\r\n### Схема работы\r\n\r\nCloudFront - это CDN от Amazon'а. По сути это географически распределенный файловый кеш. \r\n\r\nСхема его работы следующая.\r\n\r\nИсходный файл существует в единственном экземпляре и хранится в бакете S3, например в Ирландии. В свою очередь у нас настроен CloudFront с серверами в Северной Америке и Европе. В зависимости от того, где находится пользователь запрашивающий файл, он с помощью geo DNS попадает на ближайший к нему сервер CloudFront'а. Сервер сначала ищет файл в своем кеше, и если он находится (cache hit), то сразу отдает его пользователю. В случае, если файла в кеше нет (cache miss), то CloudFront идет к источнику (origin), в нашем случае это бакет S3, скачивает и сохраняет в кеш.\r\n\r\nСоответственно вместо ссылки на файл в бакете (`http://mybucket.s3.amazonaws.com/boobs.jpg`) мы должны давать пользователю ссылку на CloudFront (`http://adns8979ascnvhasd3.cloudfront.com/boobs.jpg`).\r\n\r\n### Создание дистрибуции\r\n\r\nПереходим в панель управления CloudFront.\r\n\r\n![CloudFront](images/17.png \"CloudFront\")\r\n\r\nСоздаем дистрибуцию.\r\n\r\n![Create Distribution](images/18.png \"Create Distribution\")\r\n\r\nВыбираем тип `Web`.\r\n\r\n![Web Distribution](images/19.png \"Web Distribution\")\r\n\r\nВ разделе `Origin Settings` указывается источник, где лежат исходные файлы.\r\n\r\nВ выпадающем списке `Origin Domain Name` выбираем созданный нами бакет вида `BUCKET_NAME.s3.amazonaws.com`.\r\n\r\nЗначение в поле `Origin ID` будет сгенерировано автоматически.\r\n\r\n![Origin Settings](images/20.png \"Origin Settings\")\r\n\r\nОставляем все по дефолту кроме поля `Price Class` в разделе `Distribution Settings`.\r\n\r\n![Distribution Settings Price Class](images/21.png \"Distribution Settings Price Class\")\r\n\r\nВ зависимости от требований можно выбрать в скольких регионах будут находится CDN серверы, соответственно чем больше серверов, тем выше плата за использование. Чтобы сократить стоимость укажем `Use Only US and Europe`. Если выбрать `Use All Edge Locations`, то наши файлы будут кешироваться на всех континентах. Полный список регионов указан [здесь](http://aws.amazon.com/cloudfront/details/).\r\n\r\nВ поле `Alternate Domain Names (CNAMEs)` можно указать свой красивый домен, который будет использоваться в публичных ссылках на файлы, например `cdn.example.com`. Об этом чуть позже.\r\n\r\nСоздаем дистрибуцию нажав `Create Distribution`.\r\n\r\nВ списке мы видим, что наша дистрибуция находится в статусе `In Progress`. Когда статус будет `Deployed` мы сможем протестировать работу.\r\n\r\n![Distributions](images/22.png \"Distributions\")\r\n\r\n### Добавление нашего сервера в дистрибуцию\r\n\r\nДистрибуцию нужно настроить таким образом, чтобы CloudFront в случае, если файла по какой-то причине еще нет на S3, брал его с нашего исходного сервера.\r\n\r\nДля этого выберем созданную дистрибуцию и отредактируем настройки нажав `Distribution Settings`.\r\n\r\nВо вкладке `General` указан созданный для дистрибуции домен вида `xxxxxxxx.cloudfront.com` (поле `Domain Name`).\r\n\r\n![General Distribution Settings](images/23.png \"General Distribution Settings\")\r\n\r\nСписок исходных серверов настраивается в вкладке `Origins`.\r\n\r\n![Distribution Origins](images/24.png \"Distribution Origins\")\r\n\r\nДобавим наш сервер в качестве исходного.\r\n\r\n![Create Origin](images/25.png \"Create Origin\")\r\n\r\nВ поле `Origin Domain Name` указываем домен, по которому доступен наш сервер. Поле `Origin ID` подставится автоматически. Сохраняем нажав `Create`.\r\n\r\nВо вкладке `Behaviors` указаны правила, по которым CloudFront будет искать файл, если его нет в кеше. Создадим новое правило для нашего сервера.\r\n\r\n![Distribution Behaviors](images/26.png \"Distribution Behaviors\")\r\n\r\nПоле `Path Pattern` определяет маску файла для правила. В нашем случае интересуют все файлы, поэтому указываем `*`.\r\n\r\n![Create Distribution Behavior](images/27.png \"Create Distribution Behavior\")\r\n\r\nЭто фича нужна, когда например у нас файлы .css лежат не на том же сервере, где картинки .jpg Тогда для одного сервера указываем правило *.css, для другого *.jpg. Подробнее про формат маски можно почитать [здесь](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesPathPattern).\r\n\r\nВ выпадающем списке `Origin` выбираем добавленный на предыдущем шаге сервер.\r\n\r\nСохраняем конфигурацию и переходим к тестированию.\r\n\r\n## Тестирование конфигурации\r\n\r\n### S3+CloudFront\r\n\r\nДля начала проверим, что правильно настроена связка S3+CloudFront.\r\n\r\nПереходим в панель управления S3, в левом меню выбираем созданный нами бакет, в выпадающем меню `Actions` выбираем `Upload`.\r\n\r\n![Upload file to S3](images/28.png \"Upload file to S3\")\r\n\r\nДобавляем файл `Add Files`.\r\n\r\n![Add Files](images/29.png \"Add Files\")\r\n\r\nПереходим во вкладку `Set Details` и далее в `Set Permissions` и выставляем флаг `Make everything public`, загружаем `Start Upload`.\r\n\r\n![Make Public](images/30.png \"Make Public\")\r\n\r\nПроверяем, что файл доступен по прямой ссылке на S3 `http://BUCKET_NAME.s3.amazonaws.com/elephpant.png`, где BUCKET_NAME - название бакета.\r\n\r\nДальше проверяем, что файл доступен по ссылке на CloudFront `xxxxxxxxxxx.cloudfront.net/elephpant.png`.\r\n\r\nЭтот тест провалится, потому что у нас еще не настроен прокси. Об этом в [следующем разделе](proxy.md).\r\n\r\n[Оглавление](index.html) | [Далее](proxy.html \"Настройка прокси\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n[Оглавление](index.html) | [Назад](setup.html \"Подготовка\") | [Далее](tools.html \"Инструменты\")\r\n\r\n# Настройка прокси\r\n\r\nВ ситуации, когда файл находится на S3, но уже не доступен на нашем сервере, CloudFront, проверив файл на нашем сервере, сразу вернет 404 ошибку и не пойдет искать его на S3.\r\n\r\nЭтого можно избежать, проверяя в коде существование файла локально, и генерируя ссылку соответственно либо на наш сервер, либо на CDN. Но это потребует объемных изменений.\r\n\r\nЧтобы избежать эту проблему, нужно прописать http proxy на нашем сервере.\r\n\r\n## Nginx proxy\r\n\r\nНам необходимо, чтобы nginx сначала пытался взять файл локально, а в случае, если файла нет, проксировал запрос на S3.\r\n\r\nДля этого укажем путь до прокси в конфиге nginx'а в секции server:\r\n\r\n```\r\nhttp {\r\n\r\n\t#...\r\n\t\r\n\tserver {\r\n\t\tlisten 80;\r\n\t\tserver_name example.com www.example.com;\r\n\t\t\r\n\t\t# вместо images надо указать директорию, файлы из которой переносятся на S3\r\n\t\tlocation ~ ^/images/(.*)$ {\r\n\t\t\t# сначала файл берется локально и, если он не найден, выполняется директива s3\r\n\t\t\ttry_files $uri @s3;\r\n\t\t}\r\n\t\t\r\n\t\t# выполняется только если файл не найден\r\n\t\tlocation @s3 {\r\n\t\t\r\n\t\t\t# вместо example надо указать название реального бакета\r\n\t\t\tset $s3_host 'example.s3.amazonaws.com';\r\n\t\t\tset $s3_file '$1';\r\n\t\t\t\r\n\t\t\t# для корректной работы необходимо выставить заголовки\r\n\t\t\tproxy_set_header       Host $s3_host;\r\n\t\t\tproxy_set_header       Authorization '';\r\n\t\t\tproxy_hide_header      x-amz-id-2;\r\n\t\t\tproxy_hide_header      x-amz-request-id;\r\n\t\t\tproxy_hide_header      Set-Cookie;\r\n\t\t\tproxy_ignore_headers   \"Set-Cookie\";\r\n\t\t\tproxy_buffering        off;\r\n\t\t\tproxy_intercept_errors on;\r\n\t\t\tproxy_redirect off;\r\n\t\t\t\r\n\t\t\tproxy_pass             http://$s3_bucket/images/$s3_file;\r\n\t\t}\r\n\t\t\r\n\t\t# остальные директивы location\r\n\t}\r\n}\r\n```\r\n\r\nПерезапускаем конфигурацию nginx'а:\r\n\r\n```\r\n$ service nginx reload\r\n```\r\n\r\n## Проверка\r\n\r\nЗаходим в консоль управления S3. В нашем бакете создаем папку images. В нее загружаем файл, которого точно нет на нашем сервере в директории images. Открываем файл по ссылке на CloudFront. Файл должен открыться.\r\n\r\nВ этот момент CloudFront ищет файл в своем кеше, не обнаруживает его в кеше, посылает запрос на наш сервер, nginx ищет файл локально, не обнаруживает его, отправляет запрос на S3, получает файл и отправляет его обратно CloudFront'у, тот его кеширует и отдает клиенту.\r\n\r\nСправедливости ради стоит заметить, что у этой схемы есть очевидный минус - наш сервер отправляет запрос на S3, чтобы забрать файл. Но делает он это только один раз, потому что все следующие разы клиенты получат ответ из кеша CloudFront'а.\r\n\r\nЕсли мы посмотрим в веб-инспектор, то увидим специальный заголовок `X-Cache`, в котором CloudFront указывает, откуда загружен файл - из кеша или из источника. Первый раз файл всегда берется из источника (`X-Cache: Miss from cloudfront`). Перезагрузив страницу в этом заголовке будет значение `X-Cache: Hit from cloudfront`.\r\n\r\n## Перенаправление вместо прокси\r\n\r\nЧтобы сократить издержки на проксирование запроса от CloudFront'а до S3 и обратно, можно просто перенаправлять запрос. Конфиг в таком случае выглядит так:\r\n\r\n```\r\nhttp {\r\n\r\n\t#...\r\n\t\r\n\tserver {\r\n\t\tlisten 80;\r\n\t\tserver_name example.com www.example.com;\r\n\t\t\r\n\t\tlocation ~ ^/images/(.*)$ {\r\n\t\t\ttry_files $uri @s3redirect;\r\n\t\t}\r\n\t\t\r\n\t\tlocation @s3redirect {\r\n\t\t\treturn 301 http://example.s3.amazonaws.com/images/$1;\t\t}\r\n\t\t\r\n\t\t# остальные директивы location\r\n\t}\r\n}\r\n```\r\n\r\nВ случае, если файл не найден, nginx ответит CloudFront'у редиректом (301 Moved permanently), CloudFront в свою очередь перенаправит клиента по новому URL'у.\r\n\r\nПлюс - мы не тратим траффик на отправку файла CloudFront'у.\r\n\r\nМинус - CloudFront закеширует не сам файл, а редирект на него, соответственно клиент получит файл прямиком с S3, который находится в единственном регионе, траффик с S3 дороже и скорость обычно медленнее. Вероятно что это конфигурация в результате окажется дороже, чем использование прокси.\r\n\r\n[Оглавление](index.html) | [Назад](setup.md \"Подготовка\") | [Далее](tools.md \"Инструменты\")\r\n\r\n\r\n[Оглавление](index.html) | [Назад](proxy.html \"Настройка прокси\") | [Далее](php.html \"Реализация на PHP\")\r\n\r\n# Инструменты и библиотеки для работы с S3\r\n\r\n## Графические утилиты\r\n\r\n### Cyberduck\r\n\r\nЛегкая бесплатная программа для Windows и Mac OS X.\r\n\r\n[https://cyberduck.io/](https://cyberduck.io/)\r\n\r\n![\"Cyberduck\"](images/32.png \"Cyberduck\")\r\n\r\nСоздаем `Новое подключение`, выбираем `S3`, вводим полный путь до бакета в формате `bucket.s3.amazonaws.com`, в качестве имени пользователя вводим `Access Key ID`, в качестве пароля `Secret Access Key`, полученные на этапе [подготовки](setup.md).\r\n\r\n## Библиотеки\r\n\r\n### Python\r\n\r\n#### Boto\r\n\r\nBoto - библиотека на Python предоставляющая интерфейс для Amazon Web Services.\r\n\r\nПубличный репозиторий - [https://github.com/boto/boto](https://github.com/boto/boto)\r\n\r\nДокументация - [http://docs.pythonboto.org/en/latest](http://docs.pythonboto.org/en/latest)\r\n\r\nЕдинственное требование - Python 2.6/2.7, частично поддерживвается Python 3.3/3.4.\r\n\r\nУстанавливается Boto с помощью питоновского менеджера пакетов [pip](https://pip.pypa.io/en/latest/index.html).\r\n\r\n##### Установка pip\r\n\r\n**Aptitude (Debian and Ubuntu)**\r\n\r\n```\r\n$ sudo apt-get install python-pip\r\n```\r\n\r\n**Yum (CentOS, Fedora)**\r\n\r\n```\r\n$ sudo yum install python-pip\r\n```\r\n\r\n**FreeBSD**\r\n\r\n```\r\n$ cd /usr/ports/devel/py-pip/ && make install clean\r\n```\r\n\r\n\r\n##### Устанавка boto\r\n\r\n```\r\n$ pip install boto\r\n```\r\n\r\n### PHP\r\n\r\n#### Amazon Web Services SDK\r\n\r\n\r\n\r\n\r\n\r\n## Консольные утилиты\r\n\r\n### s3put\r\n\r\nКоносльная утилита для закачки файлов на S3 на Python; поставляется вместе с Boto.\r\n\r\nМы ее будем использовать для переноса файлов с сервера на S3.\r\n\r\n#### Установка\r\n\r\nТулзу можно использовать сразу после установки boto.\r\n\r\nНо нам необходимо не только копировать файлы на S3, но и удалять их. Текущая релизация этого не умеет, поэтому надо заменить ее [моей версией](https://github.com/meetmatt/s3put/blob/master/bin/s3put).\r\n\r\nСначала убедимся, что исходный s3put лежит в `/usr/local/bin`. Если все окей, то заменяем его моим:\r\n\r\n```\r\n$ cd /usr/local/bin\r\n$ sudo cp s3put s3put.backup\r\n$ sudo wget https://raw.githubusercontent.com/meetmatt/s3put/master/s3put.py -O s3put\r\n$ sudo chmod +x s3put\r\n```\r\n\r\nПроверяем:\r\n\r\n```\r\n$ s3put | grep delete\r\n          [--header] [--region <name>] [-x/--delete] [--host <s3_host>] path [path...]\r\n        delete - delete local file after successfull upload \r\n\r\n```\r\n\r\n#### Использование\r\n\r\nНас интересуют параметры:\r\n\r\n* **-a/--access_key** - Access Key ID\r\n* **-s/--secret_key** - Secret Access Key\r\n* **-b/--bucket** - название бакета\r\n* **--region** - сокращенное название региона (колонка *Region* в [таблице](http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region))\r\n* **--delete** - удалить файлы после загрузки\r\n* **--grant** - изменить ACL файла\r\n* **--prefix** - префикс, который будет удален из пути файла\r\n\r\nДопустим мы хотим переместить фотографии юзеров из папки `/var/www/site/public/uploads/images`.\r\n\r\nСсылка на файл сейчас выглядит так: `http://example.com/uploads/images/boobs.jpg`.\r\n\r\nНам надо, чтобы файл был доступен по ссылке `http://example.s3.amazonaws.com/uploads/images/boobs.jpg`.\r\n\r\nТогда в качестве параметра `prefix` должно быть указано `/var/www/site/public/`.\r\n\r\nТак выглядит вызов s3put в нашем случае:\r\n\r\n```\r\n$ s3put --access-key LUGMNMH7B372CDN1F654 \\  \r\n        --secret-key oUkLK/9SAsU9uYwQV4oO+9iLPO3bwyVbz6yBEaaY \\  \r\n        --bucket example \\  \r\n        --region='eu-west-1' \\  \r\n        --grant='public-read' \\  \r\n        --prefix='/var/www/site/public/' \\  \r\n        --delete \\  \r\n        /var/www/site/public/uploads/images/\r\n```\r\n\r\nВ случае CloudFront файл будет доступен по ссылке `http://xxxxxxx.cloudfront.com/uploads/images/boobs.jpg`.\r\n\r\nЕсли указать путь до файла, то скопируется только он, если до директории, то рекурсивно скопируются все файлы и поддиректории в ней.\r\n\r\n#### Пример использования\r\n\r\nСкачаем какой-нибудь файл во временную директорию (здесь и далее используется Linux):\r\n\r\n```\r\n$ mkdir -p /tmp/public/uploads/images\r\n$ wget http://a0.awsstatic.com/main/images/logos/aws_logo.png -O /tmp/public/uploads/images/boobs.png\r\n```\r\n\r\nУзнаем размер файла, чтобы потом сравнить с тем, что попадет на S3:\r\n\r\n```\r\n$ ls -nl /tmp/public/uploads/images/aws_logo.png | awk '{print $5}'\r\n6258\r\n```\r\n\r\nПереместим файл на S3:\r\n\r\n```\r\n$ s3put --a LUGMNMH7B372CDN1F654 -s oUkLK/9SAsU9uYwQV4oO+9iLPO3bwyVbz6yBEaaY -b example --region='eu-west-1' --grant='public-read' --prefix='/tmp/public/' --delete /tmp/public/uploads/images/\r\nCopying /tmp/public/uploads/images/aws_logo.png to example/uploads/images/aws_logo.png\r\nUpload complete\r\nRemoving /tmp/public/uploads/images/aws_logo.png\r\n```\r\n\r\nЕсли s3put выдает ошибку `RequestTimeTooSkewed`, значит серверное время слишком расходится с временем Амазона. Синхронизируем часы по NTP:\r\n\r\n```\r\n$ sudo ntpdate 0.pool.ntp.org\r\n```\r\n\r\nПроверим, что файл был удален:\r\n\r\n```\r\n$ ls -l /tmp/public/uploads/images/\r\ntotal 0\r\n```\r\n\r\nПроверим размер файла на S3:\r\n\r\n```\r\n$ curl -I http://example.s3.amazonaws.com/uploads/images/aws_logo.png 2>&1 | grep Content-Length | awk '{print $2}'\r\n6258\r\n```\r\n\r\nВместо последнего шага можно просто открыть картинку в браузере `http://example.s3.amazonaws.com/uploads/images/aws_logo.png` или в Cyberduck.\r\n\r\n[Оглавление](index.html) | [Назад](proxy.md \"Настройка прокси\") | [Далее](php.md \"Реализация на PHP\")\r\n\r\n\r\n\r\n[Оглавление](index.html) | [Назад](tools.html \"Инструменты\") | [Далее](cron.html \"Cron скрипт\")\r\n\r\n# Реализация на PHP\r\n\r\n\r\n[Оглавление](index.html) | [Назад](tools.html \"Инструменты\") | [Далее](cron.html \"Cron скрипт\")\r\n\r\n\r\n\r\n[Оглавление](index.html) | [Назад](php.html \"Реализация на PHP\")\r\n\r\n# Cron скрипт\r\n\r\n[Оглавление](index.html) | [Назад](php.html \"Реализация на PHP\") ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}